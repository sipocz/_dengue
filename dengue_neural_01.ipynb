{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dengue_neural_01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNijCNtwbIwWsRQGjoOppng",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sipocz/_dengue/blob/main/dengue_neural_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0whmKbt9DSbQ"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#--------------scikit import \n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGsL2vrsC0rU",
        "outputId": "5b16a812-9394-49c2-dc85-668d0e58732b"
      },
      "source": [
        "#_Dengue\n",
        "_project=\"_dengue\"\n",
        "_PCVERSION_=False\n",
        "_GITHUBVERSION_=True\n",
        "_GOOGLEVERSION_=False\n",
        "if _PCVERSION_:\n",
        "    basedir=\"C:/Users/sipocz/OneDrive/Dokumentumok/GitHub\"\n",
        "\n",
        "if _GOOGLEVERSION_:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive',force_remount=True)\n",
        "    basedir=\"/content/drive/My Drive/001_AI\"\n",
        "\n",
        "if _GITHUBVERSION_:\n",
        "    !mkdir _dengue\n",
        "    files=[\"dengue_features_train.csv\",\"dengue_labels_train.csv\",\"dengue_features_test.csv\",\"/models/'model___79_0.04485_0.02581_.hdf5'\"]\n",
        "    path=\"https://raw.githubusercontent.com/sipocz/_dengue/main/\"\n",
        "    basedir=\"./\"\n",
        "    storeto=basedir+_project\n",
        "    for f in files:\n",
        "        fname=path+f\n",
        "        !rm $f\n",
        "        !wget $fname\n",
        "        !mv $f $storeto"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'dengue_features_train.csv': No such file or directory\n",
            "--2021-08-09 10:46:32--  https://raw.githubusercontent.com/sipocz/_dengue/main/dengue_features_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 287139 (280K) [text/plain]\n",
            "Saving to: ‘dengue_features_train.csv’\n",
            "\n",
            "dengue_features_tra 100%[===================>] 280.41K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-08-09 10:46:32 (17.1 MB/s) - ‘dengue_features_train.csv’ saved [287139/287139]\n",
            "\n",
            "rm: cannot remove 'dengue_labels_train.csv': No such file or directory\n",
            "--2021-08-09 10:46:32--  https://raw.githubusercontent.com/sipocz/_dengue/main/dengue_labels_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19582 (19K) [text/plain]\n",
            "Saving to: ‘dengue_labels_train.csv’\n",
            "\n",
            "dengue_labels_train 100%[===================>]  19.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-09 10:46:33 (81.5 MB/s) - ‘dengue_labels_train.csv’ saved [19582/19582]\n",
            "\n",
            "rm: cannot remove 'dengue_features_test.csv': No such file or directory\n",
            "--2021-08-09 10:46:33--  https://raw.githubusercontent.com/sipocz/_dengue/main/dengue_features_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82465 (81K) [text/plain]\n",
            "Saving to: ‘dengue_features_test.csv’\n",
            "\n",
            "dengue_features_tes 100%[===================>]  80.53K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-08-09 10:46:33 (15.4 MB/s) - ‘dengue_features_test.csv’ saved [82465/82465]\n",
            "\n",
            "rm: cannot remove '/models/model___79_0.04485_0.02581_.hdf5': No such file or directory\n",
            "--2021-08-09 10:46:33--  https://raw.githubusercontent.com/sipocz/_dengue/main//models/model___79_0.04485_0.02581_.hdf5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sipocz/_dengue/main/models/model___79_0.04485_0.02581_.hdf5 [following]\n",
            "--2021-08-09 10:46:33--  https://raw.githubusercontent.com/sipocz/_dengue/main/models/model___79_0.04485_0.02581_.hdf5\n",
            "Reusing existing connection to raw.githubusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 386732 (378K) [application/octet-stream]\n",
            "Saving to: ‘model___79_0.04485_0.02581_.hdf5’\n",
            "\n",
            "model___79_0.04485_ 100%[===================>] 377.67K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-08-09 10:46:34 (30.5 MB/s) - ‘model___79_0.04485_0.02581_.hdf5’ saved [386732/386732]\n",
            "\n",
            "mv: cannot stat '/models/model___79_0.04485_0.02581_.hdf5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eptb9-bvDGXL"
      },
      "source": [
        "\n",
        "features_train=basedir+_project+\"/\"+\"dengue_features_train.csv\"\n",
        "labels_train=basedir+_project+\"/\"+\"dengue_labels_train.csv\"\n",
        "features_test=basedir+_project+\"/\"+\"dengue_features_test.csv\"\n",
        "\n",
        "\n",
        "X_train=pd.read_csv(features_train)\n",
        "y_train=pd.read_csv(labels_train)\n",
        "X_test=pd.read_csv(features_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRYy2LdXria_"
      },
      "source": [
        "X_train[\"total_cases\"]=y_train[\"total_cases\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24pyp2CPDZ8u"
      },
      "source": [
        "X_test.fillna(method=\"bfill\", inplace=True)\n",
        "X_train.fillna(method=\"bfill\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhcMI8ZeTx69"
      },
      "source": [
        "\n",
        "X_train_sj=X_train[X_train.city == \"sj\"]\n",
        "X_train_iq=X_train[X_train.city == \"iq\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z2gUXspSzAi"
      },
      "source": [
        "\n",
        "X_test_sj=X_test[X_test.city == \"sj\"]\n",
        "X_test_iq=X_test[X_test.city == \"iq\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV9fDqjQNKzr"
      },
      "source": [
        "def build_training_data(dataset,labelset, history_size = 5, target_size = 23):\n",
        "    '''\n",
        "    source: https://www.mikulskibartosz.name/how-to-split-a-data-frame-into-time-series-for-lstm-deep-neural-network/\n",
        "    '''\n",
        "    start_index = history_size\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for i in range(start_index, end_index):\n",
        "        indices = range(i - history_size, i, 1)\n",
        "        #print(indices)\n",
        "        row=[]\n",
        "        for j in indices:\n",
        "            row=row+list(dataset.iloc[j])\n",
        "        data.append(row)\n",
        "\n",
        "    #label \n",
        "    for i in range(start_index, end_index):\n",
        "        indices = range(i, i+target_size, 1)\n",
        "        #print(indices)\n",
        "        row=[]\n",
        "        for j in indices:\n",
        "            row=row+list(labelset.iloc[j])\n",
        "        labels.append(row)\n",
        "\n",
        "\n",
        "    data = np.array(data)\n",
        "    labels=np.array(labels)\n",
        "    #data = data.reshape((-1, 1))\n",
        "    return data, labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z1tYJIoDbe-"
      },
      "source": [
        "def datapipe_Xy(Xinp,yinp):\n",
        "    X=Xinp.copy(deep=True)\n",
        "    y=yinp.copy(deep=True)\n",
        "    prediktorok=['ndvi_ne', 'ndvi_nw',\n",
        "       'ndvi_se', 'ndvi_sw',\n",
        "       'precipitation_amt_mm', 'reanalysis_air_temp_k',\n",
        "       'reanalysis_avg_temp_k', 'reanalysis_dew_point_temp_k',\n",
        "       'reanalysis_max_air_temp_k', 'reanalysis_min_air_temp_k',\n",
        "       'reanalysis_precip_amt_kg_per_m2',\n",
        "       'reanalysis_relative_humidity_percent', 'reanalysis_sat_precip_amt_mm',\n",
        "       'reanalysis_specific_humidity_g_per_kg', 'reanalysis_tdtr_k',\n",
        "       'station_avg_temp_c', 'station_diur_temp_rng_c', 'station_max_temp_c',\n",
        "       'station_min_temp_c', 'station_precip_mm']\n",
        "    X[\"reanalysis_air_temp_k\"]=X[\"reanalysis_air_temp_k\"]-273.15\n",
        "    X[\"reanalysis_avg_temp_k\"]=X[\"reanalysis_avg_temp_k\"]-273.15\n",
        "    X['reanalysis_max_air_temp_k']=X['reanalysis_max_air_temp_k']-273.15\n",
        "    X[\"reanalysis_min_air_temp_k\"]=X[\"reanalysis_min_air_temp_k\"]-273.15\n",
        "    X[\"reanalysis_dew_point_temp_k\"]=X[\"reanalysis_dew_point_temp_k\"]-273.15\n",
        "    X[\"ndvi_N\"]=(X[\"ndvi_ne\"]+X[\"ndvi_nw\"])/2\n",
        "    X[\"ndvi_S\"]=(X[\"ndvi_se\"]+X[\"ndvi_sw\"])/2\n",
        "\n",
        "\n",
        "    Xprediktor=['ndvi_N','ndvi_S',\n",
        "       'precipitation_amt_mm', 'reanalysis_air_temp_k',\n",
        "       'reanalysis_avg_temp_k', 'reanalysis_dew_point_temp_k',\n",
        "       'reanalysis_max_air_temp_k', 'reanalysis_min_air_temp_k',\n",
        "       'reanalysis_precip_amt_kg_per_m2',\n",
        "       'reanalysis_relative_humidity_percent', 'reanalysis_sat_precip_amt_mm',\n",
        "       'reanalysis_specific_humidity_g_per_kg', 'reanalysis_tdtr_k',\n",
        "       'station_avg_temp_c', 'station_diur_temp_rng_c', 'station_max_temp_c',\n",
        "       'station_min_temp_c', 'station_precip_mm']\n",
        "    \n",
        "    yprediktor=[\"total_cases\"]\n",
        "    \n",
        "    return(X[Xprediktor],y[yprediktor])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5wV38Y_Nwj6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5weMYMnL0Ts"
      },
      "source": [
        "#test\n",
        "X2,y2=datapipe_Xy(X_train_sj,X_train_sj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "o3NdSvd9Nxaq",
        "outputId": "1b98f7fc-edb4-472e-f85e-794f5e9c9d7f"
      },
      "source": [
        "y2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_cases</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   total_cases\n",
              "0            4\n",
              "1            5\n",
              "2            4\n",
              "3            3\n",
              "4            6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "scTNFd-XLVBv",
        "outputId": "db77d0eb-a7ee-4d4e-cb0a-eed03c9fa9c0"
      },
      "source": [
        "X2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ndvi_N</th>\n",
              "      <th>ndvi_S</th>\n",
              "      <th>precipitation_amt_mm</th>\n",
              "      <th>reanalysis_air_temp_k</th>\n",
              "      <th>reanalysis_avg_temp_k</th>\n",
              "      <th>reanalysis_dew_point_temp_k</th>\n",
              "      <th>reanalysis_max_air_temp_k</th>\n",
              "      <th>reanalysis_min_air_temp_k</th>\n",
              "      <th>reanalysis_precip_amt_kg_per_m2</th>\n",
              "      <th>reanalysis_relative_humidity_percent</th>\n",
              "      <th>reanalysis_sat_precip_amt_mm</th>\n",
              "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
              "      <th>reanalysis_tdtr_k</th>\n",
              "      <th>station_avg_temp_c</th>\n",
              "      <th>station_diur_temp_rng_c</th>\n",
              "      <th>station_max_temp_c</th>\n",
              "      <th>station_min_temp_c</th>\n",
              "      <th>station_precip_mm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.113162</td>\n",
              "      <td>0.188050</td>\n",
              "      <td>12.42</td>\n",
              "      <td>24.422857</td>\n",
              "      <td>24.592857</td>\n",
              "      <td>19.264286</td>\n",
              "      <td>26.65</td>\n",
              "      <td>22.75</td>\n",
              "      <td>32.00</td>\n",
              "      <td>73.365714</td>\n",
              "      <td>12.42</td>\n",
              "      <td>14.012857</td>\n",
              "      <td>2.628571</td>\n",
              "      <td>25.442857</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>29.4</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.156037</td>\n",
              "      <td>0.158921</td>\n",
              "      <td>22.82</td>\n",
              "      <td>25.061429</td>\n",
              "      <td>25.292857</td>\n",
              "      <td>20.801429</td>\n",
              "      <td>27.75</td>\n",
              "      <td>23.25</td>\n",
              "      <td>17.94</td>\n",
              "      <td>77.368571</td>\n",
              "      <td>22.82</td>\n",
              "      <td>15.372857</td>\n",
              "      <td>2.371429</td>\n",
              "      <td>26.714286</td>\n",
              "      <td>6.371429</td>\n",
              "      <td>31.7</td>\n",
              "      <td>22.2</td>\n",
              "      <td>8.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.102608</td>\n",
              "      <td>0.164021</td>\n",
              "      <td>34.54</td>\n",
              "      <td>25.631429</td>\n",
              "      <td>25.728571</td>\n",
              "      <td>22.284286</td>\n",
              "      <td>27.35</td>\n",
              "      <td>24.15</td>\n",
              "      <td>26.10</td>\n",
              "      <td>82.052857</td>\n",
              "      <td>34.54</td>\n",
              "      <td>16.848571</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>26.714286</td>\n",
              "      <td>6.485714</td>\n",
              "      <td>32.2</td>\n",
              "      <td>22.8</td>\n",
              "      <td>41.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.186850</td>\n",
              "      <td>0.231721</td>\n",
              "      <td>15.36</td>\n",
              "      <td>25.837143</td>\n",
              "      <td>26.078571</td>\n",
              "      <td>22.160000</td>\n",
              "      <td>28.25</td>\n",
              "      <td>23.85</td>\n",
              "      <td>13.90</td>\n",
              "      <td>80.337143</td>\n",
              "      <td>15.36</td>\n",
              "      <td>16.672857</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>27.471429</td>\n",
              "      <td>6.771429</td>\n",
              "      <td>33.3</td>\n",
              "      <td>23.3</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.229200</td>\n",
              "      <td>0.249270</td>\n",
              "      <td>7.52</td>\n",
              "      <td>26.368571</td>\n",
              "      <td>26.514286</td>\n",
              "      <td>22.671429</td>\n",
              "      <td>28.75</td>\n",
              "      <td>24.35</td>\n",
              "      <td>12.20</td>\n",
              "      <td>80.460000</td>\n",
              "      <td>7.52</td>\n",
              "      <td>17.210000</td>\n",
              "      <td>3.014286</td>\n",
              "      <td>28.942857</td>\n",
              "      <td>9.371429</td>\n",
              "      <td>35.0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>5.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ndvi_N    ndvi_S  ...  station_min_temp_c  station_precip_mm\n",
              "0  0.113162  0.188050  ...                20.0               16.0\n",
              "1  0.156037  0.158921  ...                22.2                8.6\n",
              "2  0.102608  0.164021  ...                22.8               41.4\n",
              "3  0.186850  0.231721  ...                23.3                4.0\n",
              "4  0.229200  0.249270  ...                23.9                5.8\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI4PcCj8kDf2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATkEEguEb6W6"
      },
      "source": [
        "XSJ,ySJ=build_training_data(X2,y2,4,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlgmt1SvcCj2",
        "outputId": "221f4e65-3171-4f29-b7fe-5f26d2a064ad"
      },
      "source": [
        "len(XSJ)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRDYJ9lQjOX5",
        "outputId": "c51b54d7-2010-420d-a842-598cbb6b86b5"
      },
      "source": [
        "ySJ[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD-sOBFYmbkG"
      },
      "source": [
        "from keras.backend import clear_session\n",
        "from keras.layers import InputLayer, Dense, LSTM, Input, Dropout,Flatten,Bidirectional\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import SGD,Adam,Adamax,Nadam,Ftrl,Adadelta,Adagrad,Nadam,RMSprop\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.backend import clear_session\n",
        "from tensorflow.keras.losses import mean_absolute_percentage_error, huber,kld\n",
        "#import tensorflow_addons as tfa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3ebXumcmtjE",
        "outputId": "e2fee109-ffd4-4394-e777-15ca03705ba6"
      },
      "source": [
        "clear_session() \n",
        "dropout_1_rate=0.1\n",
        "input_size=len(XSJ[0]) # timesteps\n",
        "output_size=len(ySJ[0]) # features\n",
        "learning_rate=0.003\n",
        "\n",
        "inputs=Input(shape=(input_size))\n",
        "o1=Dense(300,activation=\"relu\",)(inputs)\n",
        "o2=Dense(20,activation=\"sigmoid\",)(o1)\n",
        "\n",
        "o3=Dense(100,activation=\"relu\",)(o2)\n",
        "result=Dense(output_size,activation=\"sigmoid\",)(o3)\n",
        "#dropout1=Dropout(rate=dropout_1_rate)(layer2)\n",
        "#result=Dense(output_size,activation=\"sigmoid\")(dropout1)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=result)\n",
        "model.compile(optimizer=Adamax(learning_rate=learning_rate), loss=\"mae\")  #RMSprop\n",
        "model.summary()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 72)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 300)               21900     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                6020      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               2100      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 30,121\n",
            "Trainable params: 30,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmoQ0-8Incy8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6h8N5NrpbwH"
      },
      "source": [
        "\n",
        "x_scaler = MinMaxScaler()\n",
        "XSJ_scale = pd.DataFrame(x_scaler.fit_transform(XSJ))\n",
        "\n",
        "y_scaler=MinMaxScaler()\n",
        "ySJ_scale=pd.DataFrame(y_scaler.fit_transform(ySJ))"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "EZ6f8mr5w5uV",
        "outputId": "3a34fa78-2051-4805-b8bd-04f8b43236a6"
      },
      "source": [
        "ySJ_scale"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.004338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.008677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.010846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.021692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>0.006508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>0.008677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>0.006508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>0.002169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>0.006508</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>931 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0\n",
              "0    0.013015\n",
              "1    0.004338\n",
              "2    0.008677\n",
              "3    0.010846\n",
              "4    0.021692\n",
              "..        ...\n",
              "926  0.006508\n",
              "927  0.008677\n",
              "928  0.006508\n",
              "929  0.002169\n",
              "930  0.006508\n",
              "\n",
              "[931 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXBjot_lP3Mv"
      },
      "source": [
        "!rm model*"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q5ghx0VORBA"
      },
      "source": [
        "fname=\"./model__\"\n",
        "callbacks = [#callback_LR,\n",
        "       \n",
        "        ModelCheckpoint(filepath=fname+\"_{epoch}\"+\"_{loss:.5f}_{val_loss:.5f}_.hdf5\", monitor='val_loss',\n",
        "                        verbose=2, save_best_only=True, mode='min')]"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "WYy19t3r0255",
        "outputId": "dccccc8a-8a2e-49b9-b8c1-89ad0a63f490"
      },
      "source": [
        "XSJ_scale"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.578732</td>\n",
              "      <td>0.506411</td>\n",
              "      <td>0.031797</td>\n",
              "      <td>0.261008</td>\n",
              "      <td>0.269185</td>\n",
              "      <td>0.339933</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.452055</td>\n",
              "      <td>0.056091</td>\n",
              "      <td>0.318138</td>\n",
              "      <td>0.031797</td>\n",
              "      <td>0.297392</td>\n",
              "      <td>0.413953</td>\n",
              "      <td>0.359684</td>\n",
              "      <td>0.440318</td>\n",
              "      <td>0.303371</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.052305</td>\n",
              "      <td>0.637045</td>\n",
              "      <td>0.431714</td>\n",
              "      <td>0.058423</td>\n",
              "      <td>0.362993</td>\n",
              "      <td>0.384888</td>\n",
              "      <td>0.528474</td>\n",
              "      <td>0.476923</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.031446</td>\n",
              "      <td>0.510214</td>\n",
              "      <td>0.058423</td>\n",
              "      <td>0.473460</td>\n",
              "      <td>0.330233</td>\n",
              "      <td>0.535573</td>\n",
              "      <td>0.342175</td>\n",
              "      <td>0.561798</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.028114</td>\n",
              "      <td>0.564377</td>\n",
              "      <td>0.444793</td>\n",
              "      <td>0.088428</td>\n",
              "      <td>0.454027</td>\n",
              "      <td>0.456907</td>\n",
              "      <td>0.710356</td>\n",
              "      <td>0.415385</td>\n",
              "      <td>0.643836</td>\n",
              "      <td>0.045749</td>\n",
              "      <td>0.734988</td>\n",
              "      <td>0.088428</td>\n",
              "      <td>0.664509</td>\n",
              "      <td>0.306977</td>\n",
              "      <td>0.535573</td>\n",
              "      <td>0.363395</td>\n",
              "      <td>0.617978</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.135338</td>\n",
              "      <td>0.678953</td>\n",
              "      <td>0.618401</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.486881</td>\n",
              "      <td>0.514758</td>\n",
              "      <td>0.695111</td>\n",
              "      <td>0.553846</td>\n",
              "      <td>0.602740</td>\n",
              "      <td>0.024365</td>\n",
              "      <td>0.652660</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.641761</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.640316</td>\n",
              "      <td>0.416446</td>\n",
              "      <td>0.741573</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.013076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.637045</td>\n",
              "      <td>0.431714</td>\n",
              "      <td>0.058423</td>\n",
              "      <td>0.362993</td>\n",
              "      <td>0.384888</td>\n",
              "      <td>0.528474</td>\n",
              "      <td>0.476923</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.031446</td>\n",
              "      <td>0.510214</td>\n",
              "      <td>0.058423</td>\n",
              "      <td>0.473460</td>\n",
              "      <td>0.330233</td>\n",
              "      <td>0.535573</td>\n",
              "      <td>0.342175</td>\n",
              "      <td>0.561798</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.028114</td>\n",
              "      <td>0.564377</td>\n",
              "      <td>0.444793</td>\n",
              "      <td>0.088428</td>\n",
              "      <td>0.454027</td>\n",
              "      <td>0.456907</td>\n",
              "      <td>0.710356</td>\n",
              "      <td>0.415385</td>\n",
              "      <td>0.643836</td>\n",
              "      <td>0.045749</td>\n",
              "      <td>0.734988</td>\n",
              "      <td>0.088428</td>\n",
              "      <td>0.664509</td>\n",
              "      <td>0.306977</td>\n",
              "      <td>0.535573</td>\n",
              "      <td>0.363395</td>\n",
              "      <td>0.617978</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.135338</td>\n",
              "      <td>0.678953</td>\n",
              "      <td>0.618401</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.486881</td>\n",
              "      <td>0.514758</td>\n",
              "      <td>0.695111</td>\n",
              "      <td>0.553846</td>\n",
              "      <td>0.602740</td>\n",
              "      <td>0.024365</td>\n",
              "      <td>0.652660</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.641761</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.640316</td>\n",
              "      <td>0.416446</td>\n",
              "      <td>0.741573</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.013076</td>\n",
              "      <td>0.736552</td>\n",
              "      <td>0.663403</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.571755</td>\n",
              "      <td>0.586777</td>\n",
              "      <td>0.757841</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.671233</td>\n",
              "      <td>0.021385</td>\n",
              "      <td>0.658555</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.711300</td>\n",
              "      <td>0.539535</td>\n",
              "      <td>0.843874</td>\n",
              "      <td>0.899204</td>\n",
              "      <td>0.932584</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.018960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.564377</td>\n",
              "      <td>0.444793</td>\n",
              "      <td>0.088428</td>\n",
              "      <td>0.454027</td>\n",
              "      <td>0.456907</td>\n",
              "      <td>0.710356</td>\n",
              "      <td>0.415385</td>\n",
              "      <td>0.643836</td>\n",
              "      <td>0.045749</td>\n",
              "      <td>0.734988</td>\n",
              "      <td>0.088428</td>\n",
              "      <td>0.664509</td>\n",
              "      <td>0.306977</td>\n",
              "      <td>0.535573</td>\n",
              "      <td>0.363395</td>\n",
              "      <td>0.617978</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.135338</td>\n",
              "      <td>0.678953</td>\n",
              "      <td>0.618401</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.486881</td>\n",
              "      <td>0.514758</td>\n",
              "      <td>0.695111</td>\n",
              "      <td>0.553846</td>\n",
              "      <td>0.602740</td>\n",
              "      <td>0.024365</td>\n",
              "      <td>0.652660</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.641761</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.640316</td>\n",
              "      <td>0.416446</td>\n",
              "      <td>0.741573</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.013076</td>\n",
              "      <td>0.736552</td>\n",
              "      <td>0.663403</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.571755</td>\n",
              "      <td>0.586777</td>\n",
              "      <td>0.757841</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.671233</td>\n",
              "      <td>0.021385</td>\n",
              "      <td>0.658555</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.711300</td>\n",
              "      <td>0.539535</td>\n",
              "      <td>0.843874</td>\n",
              "      <td>0.899204</td>\n",
              "      <td>0.932584</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.018960</td>\n",
              "      <td>0.620503</td>\n",
              "      <td>0.583288</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.589551</td>\n",
              "      <td>0.603306</td>\n",
              "      <td>0.761521</td>\n",
              "      <td>0.707692</td>\n",
              "      <td>0.753425</td>\n",
              "      <td>0.046433</td>\n",
              "      <td>0.631272</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.711670</td>\n",
              "      <td>0.241860</td>\n",
              "      <td>0.729249</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.865169</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.127820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.678953</td>\n",
              "      <td>0.618401</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.486881</td>\n",
              "      <td>0.514758</td>\n",
              "      <td>0.695111</td>\n",
              "      <td>0.553846</td>\n",
              "      <td>0.602740</td>\n",
              "      <td>0.024365</td>\n",
              "      <td>0.652660</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.641761</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.640316</td>\n",
              "      <td>0.416446</td>\n",
              "      <td>0.741573</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.013076</td>\n",
              "      <td>0.736552</td>\n",
              "      <td>0.663403</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.571755</td>\n",
              "      <td>0.586777</td>\n",
              "      <td>0.757841</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.671233</td>\n",
              "      <td>0.021385</td>\n",
              "      <td>0.658555</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.711300</td>\n",
              "      <td>0.539535</td>\n",
              "      <td>0.843874</td>\n",
              "      <td>0.899204</td>\n",
              "      <td>0.932584</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.018960</td>\n",
              "      <td>0.620503</td>\n",
              "      <td>0.583288</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.589551</td>\n",
              "      <td>0.603306</td>\n",
              "      <td>0.761521</td>\n",
              "      <td>0.707692</td>\n",
              "      <td>0.753425</td>\n",
              "      <td>0.046433</td>\n",
              "      <td>0.631272</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.711670</td>\n",
              "      <td>0.241860</td>\n",
              "      <td>0.729249</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.865169</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.127820</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.556728</td>\n",
              "      <td>0.008909</td>\n",
              "      <td>0.522017</td>\n",
              "      <td>0.513577</td>\n",
              "      <td>0.763273</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.698630</td>\n",
              "      <td>0.067660</td>\n",
              "      <td>0.732451</td>\n",
              "      <td>0.008909</td>\n",
              "      <td>0.714444</td>\n",
              "      <td>0.223256</td>\n",
              "      <td>0.632411</td>\n",
              "      <td>0.416446</td>\n",
              "      <td>0.617978</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.097091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.736552</td>\n",
              "      <td>0.663403</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.571755</td>\n",
              "      <td>0.586777</td>\n",
              "      <td>0.757841</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.671233</td>\n",
              "      <td>0.021385</td>\n",
              "      <td>0.658555</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.711300</td>\n",
              "      <td>0.539535</td>\n",
              "      <td>0.843874</td>\n",
              "      <td>0.899204</td>\n",
              "      <td>0.932584</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.018960</td>\n",
              "      <td>0.620503</td>\n",
              "      <td>0.583288</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.589551</td>\n",
              "      <td>0.603306</td>\n",
              "      <td>0.761521</td>\n",
              "      <td>0.707692</td>\n",
              "      <td>0.753425</td>\n",
              "      <td>0.046433</td>\n",
              "      <td>0.631272</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.711670</td>\n",
              "      <td>0.241860</td>\n",
              "      <td>0.729249</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.865169</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.127820</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.556728</td>\n",
              "      <td>0.008909</td>\n",
              "      <td>0.522017</td>\n",
              "      <td>0.513577</td>\n",
              "      <td>0.763273</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.698630</td>\n",
              "      <td>0.067660</td>\n",
              "      <td>0.732451</td>\n",
              "      <td>0.008909</td>\n",
              "      <td>0.714444</td>\n",
              "      <td>0.223256</td>\n",
              "      <td>0.632411</td>\n",
              "      <td>0.416446</td>\n",
              "      <td>0.617978</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.097091</td>\n",
              "      <td>0.523427</td>\n",
              "      <td>0.388962</td>\n",
              "      <td>0.386892</td>\n",
              "      <td>0.583390</td>\n",
              "      <td>0.564345</td>\n",
              "      <td>0.844927</td>\n",
              "      <td>0.430769</td>\n",
              "      <td>0.794521</td>\n",
              "      <td>0.052585</td>\n",
              "      <td>0.798464</td>\n",
              "      <td>0.386892</td>\n",
              "      <td>0.810616</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>0.764822</td>\n",
              "      <td>0.586207</td>\n",
              "      <td>0.808989</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.068977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>0.265885</td>\n",
              "      <td>0.632176</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.314397</td>\n",
              "      <td>0.321133</td>\n",
              "      <td>0.428246</td>\n",
              "      <td>0.276923</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.014549</td>\n",
              "      <td>0.386276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.365452</td>\n",
              "      <td>0.172093</td>\n",
              "      <td>0.284585</td>\n",
              "      <td>0.233422</td>\n",
              "      <td>0.179775</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.374852</td>\n",
              "      <td>0.445983</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291809</td>\n",
              "      <td>0.323495</td>\n",
              "      <td>0.350797</td>\n",
              "      <td>0.323077</td>\n",
              "      <td>0.506849</td>\n",
              "      <td>0.011323</td>\n",
              "      <td>0.284275</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291474</td>\n",
              "      <td>0.302326</td>\n",
              "      <td>0.262846</td>\n",
              "      <td>0.180371</td>\n",
              "      <td>0.123596</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.042171</td>\n",
              "      <td>0.303140</td>\n",
              "      <td>0.508115</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.309833</td>\n",
              "      <td>0.312869</td>\n",
              "      <td>0.418258</td>\n",
              "      <td>0.323077</td>\n",
              "      <td>0.397260</td>\n",
              "      <td>0.011394</td>\n",
              "      <td>0.381272</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.357130</td>\n",
              "      <td>0.409302</td>\n",
              "      <td>0.314229</td>\n",
              "      <td>0.294430</td>\n",
              "      <td>0.303371</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.042498</td>\n",
              "      <td>0.110235</td>\n",
              "      <td>0.346851</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264659</td>\n",
              "      <td>0.252656</td>\n",
              "      <td>0.313299</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.479452</td>\n",
              "      <td>0.016442</td>\n",
              "      <td>0.249452</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259663</td>\n",
              "      <td>0.237209</td>\n",
              "      <td>0.343874</td>\n",
              "      <td>0.238727</td>\n",
              "      <td>0.247191</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.014384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>0.374852</td>\n",
              "      <td>0.445983</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291809</td>\n",
              "      <td>0.323495</td>\n",
              "      <td>0.350797</td>\n",
              "      <td>0.323077</td>\n",
              "      <td>0.506849</td>\n",
              "      <td>0.011323</td>\n",
              "      <td>0.284275</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291474</td>\n",
              "      <td>0.302326</td>\n",
              "      <td>0.262846</td>\n",
              "      <td>0.180371</td>\n",
              "      <td>0.123596</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.042171</td>\n",
              "      <td>0.303140</td>\n",
              "      <td>0.508115</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.309833</td>\n",
              "      <td>0.312869</td>\n",
              "      <td>0.418258</td>\n",
              "      <td>0.323077</td>\n",
              "      <td>0.397260</td>\n",
              "      <td>0.011394</td>\n",
              "      <td>0.381272</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.357130</td>\n",
              "      <td>0.409302</td>\n",
              "      <td>0.314229</td>\n",
              "      <td>0.294430</td>\n",
              "      <td>0.303371</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.042498</td>\n",
              "      <td>0.110235</td>\n",
              "      <td>0.346851</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264659</td>\n",
              "      <td>0.252656</td>\n",
              "      <td>0.313299</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.479452</td>\n",
              "      <td>0.016442</td>\n",
              "      <td>0.249452</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259663</td>\n",
              "      <td>0.237209</td>\n",
              "      <td>0.343874</td>\n",
              "      <td>0.238727</td>\n",
              "      <td>0.247191</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.014384</td>\n",
              "      <td>0.471982</td>\n",
              "      <td>0.267319</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234086</td>\n",
              "      <td>0.218418</td>\n",
              "      <td>0.314351</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.315068</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.296545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261698</td>\n",
              "      <td>0.818605</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.466844</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.001635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>0.303140</td>\n",
              "      <td>0.508115</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.309833</td>\n",
              "      <td>0.312869</td>\n",
              "      <td>0.418258</td>\n",
              "      <td>0.323077</td>\n",
              "      <td>0.397260</td>\n",
              "      <td>0.011394</td>\n",
              "      <td>0.381272</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.357130</td>\n",
              "      <td>0.409302</td>\n",
              "      <td>0.314229</td>\n",
              "      <td>0.294430</td>\n",
              "      <td>0.303371</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.042498</td>\n",
              "      <td>0.110235</td>\n",
              "      <td>0.346851</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264659</td>\n",
              "      <td>0.252656</td>\n",
              "      <td>0.313299</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.479452</td>\n",
              "      <td>0.016442</td>\n",
              "      <td>0.249452</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259663</td>\n",
              "      <td>0.237209</td>\n",
              "      <td>0.343874</td>\n",
              "      <td>0.238727</td>\n",
              "      <td>0.247191</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.014384</td>\n",
              "      <td>0.471982</td>\n",
              "      <td>0.267319</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234086</td>\n",
              "      <td>0.218418</td>\n",
              "      <td>0.314351</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.315068</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.296545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261698</td>\n",
              "      <td>0.818605</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.466844</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.001635</td>\n",
              "      <td>0.450629</td>\n",
              "      <td>0.802103</td>\n",
              "      <td>0.069611</td>\n",
              "      <td>0.162902</td>\n",
              "      <td>0.139315</td>\n",
              "      <td>0.300859</td>\n",
              "      <td>0.292308</td>\n",
              "      <td>0.246575</td>\n",
              "      <td>0.013234</td>\n",
              "      <td>0.360433</td>\n",
              "      <td>0.069611</td>\n",
              "      <td>0.249676</td>\n",
              "      <td>0.497674</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.233422</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.005884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>0.110235</td>\n",
              "      <td>0.346851</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264659</td>\n",
              "      <td>0.252656</td>\n",
              "      <td>0.313299</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.479452</td>\n",
              "      <td>0.016442</td>\n",
              "      <td>0.249452</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259663</td>\n",
              "      <td>0.237209</td>\n",
              "      <td>0.343874</td>\n",
              "      <td>0.238727</td>\n",
              "      <td>0.247191</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.014384</td>\n",
              "      <td>0.471982</td>\n",
              "      <td>0.267319</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234086</td>\n",
              "      <td>0.218418</td>\n",
              "      <td>0.314351</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.315068</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.296545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261698</td>\n",
              "      <td>0.818605</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.466844</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.001635</td>\n",
              "      <td>0.450629</td>\n",
              "      <td>0.802103</td>\n",
              "      <td>0.069611</td>\n",
              "      <td>0.162902</td>\n",
              "      <td>0.139315</td>\n",
              "      <td>0.300859</td>\n",
              "      <td>0.292308</td>\n",
              "      <td>0.246575</td>\n",
              "      <td>0.013234</td>\n",
              "      <td>0.360433</td>\n",
              "      <td>0.069611</td>\n",
              "      <td>0.249676</td>\n",
              "      <td>0.497674</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.233422</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.005884</td>\n",
              "      <td>0.387533</td>\n",
              "      <td>0.262355</td>\n",
              "      <td>0.009780</td>\n",
              "      <td>0.342231</td>\n",
              "      <td>0.349469</td>\n",
              "      <td>0.440687</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.534247</td>\n",
              "      <td>0.006433</td>\n",
              "      <td>0.377365</td>\n",
              "      <td>0.009780</td>\n",
              "      <td>0.381542</td>\n",
              "      <td>0.441860</td>\n",
              "      <td>0.470356</td>\n",
              "      <td>0.424403</td>\n",
              "      <td>0.438202</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.001635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>0.471982</td>\n",
              "      <td>0.267319</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234086</td>\n",
              "      <td>0.218418</td>\n",
              "      <td>0.314351</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.315068</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.296545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261698</td>\n",
              "      <td>0.818605</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.466844</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.001635</td>\n",
              "      <td>0.450629</td>\n",
              "      <td>0.802103</td>\n",
              "      <td>0.069611</td>\n",
              "      <td>0.162902</td>\n",
              "      <td>0.139315</td>\n",
              "      <td>0.300859</td>\n",
              "      <td>0.292308</td>\n",
              "      <td>0.246575</td>\n",
              "      <td>0.013234</td>\n",
              "      <td>0.360433</td>\n",
              "      <td>0.069611</td>\n",
              "      <td>0.249676</td>\n",
              "      <td>0.497674</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.233422</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.005884</td>\n",
              "      <td>0.387533</td>\n",
              "      <td>0.262355</td>\n",
              "      <td>0.009780</td>\n",
              "      <td>0.342231</td>\n",
              "      <td>0.349469</td>\n",
              "      <td>0.440687</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.534247</td>\n",
              "      <td>0.006433</td>\n",
              "      <td>0.377365</td>\n",
              "      <td>0.009780</td>\n",
              "      <td>0.381542</td>\n",
              "      <td>0.441860</td>\n",
              "      <td>0.470356</td>\n",
              "      <td>0.424403</td>\n",
              "      <td>0.438202</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.001635</td>\n",
              "      <td>0.283407</td>\n",
              "      <td>0.381873</td>\n",
              "      <td>0.043420</td>\n",
              "      <td>0.242984</td>\n",
              "      <td>0.239669</td>\n",
              "      <td>0.379008</td>\n",
              "      <td>0.246154</td>\n",
              "      <td>0.438356</td>\n",
              "      <td>0.061350</td>\n",
              "      <td>0.397861</td>\n",
              "      <td>0.043420</td>\n",
              "      <td>0.319586</td>\n",
              "      <td>0.269767</td>\n",
              "      <td>0.298419</td>\n",
              "      <td>0.220159</td>\n",
              "      <td>0.303371</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.100360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>931 rows × 72 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2   ...        69        70        71\n",
              "0    0.578732  0.506411  0.031797  ...  0.741573  0.705128  0.013076\n",
              "1    0.637045  0.431714  0.058423  ...  0.932584  0.782051  0.018960\n",
              "2    0.564377  0.444793  0.088428  ...  0.865169  0.782051  0.127820\n",
              "3    0.678953  0.618401  0.039324  ...  0.617978  0.705128  0.097091\n",
              "4    0.736552  0.663403  0.019252  ...  0.808989  0.641026  0.068977\n",
              "..        ...       ...       ...  ...       ...       ...       ...\n",
              "926  0.265885  0.632176  0.000000  ...  0.247191  0.564103  0.014384\n",
              "927  0.374852  0.445983  0.000000  ...  0.370787  0.358974  0.001635\n",
              "928  0.303140  0.508115  0.000000  ...  0.370787  0.423077  0.005884\n",
              "929  0.110235  0.346851  0.000000  ...  0.438202  0.564103  0.001635\n",
              "930  0.471982  0.267319  0.000000  ...  0.303371  0.500000  0.100360\n",
              "\n",
              "[931 rows x 72 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9zR35uKHvNu",
        "outputId": "90a0ff6b-d240-43a7-860b-0314d652f8ad"
      },
      "source": [
        "history = model.fit(\n",
        "    x=XSJ_scale,\n",
        "    y=ySJ_scale,\n",
        "    validation_split=0.3,\n",
        "    epochs=200,\n",
        "    batch_size=7,\n",
        "    callbacks=callbacks,shuffle=False\n",
        "   )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "93/93 [==============================] - 0s 4ms/step - loss: 0.0325 - val_loss: 0.0299\n",
            "\n",
            "Epoch 00001: val_loss improved from 0.03119 to 0.02994, saving model to ./model___1_0.03254_0.02994_.hdf5\n",
            "Epoch 2/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0326\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.02994\n",
            "Epoch 3/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.0288\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.02994 to 0.02879, saving model to ./model___3_0.03306_0.02879_.hdf5\n",
            "Epoch 4/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0307\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.02879\n",
            "Epoch 5/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.0306\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.02879\n",
            "Epoch 6/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0294\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.02879\n",
            "Epoch 7/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0325\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.02879\n",
            "Epoch 8/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.0291\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.02879\n",
            "Epoch 9/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0304\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.02879\n",
            "Epoch 10/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0333\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.02879\n",
            "Epoch 11/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0318\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.02879\n",
            "Epoch 12/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0302\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.02879\n",
            "Epoch 13/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0317\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.02879\n",
            "Epoch 14/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0313\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.02879\n",
            "Epoch 15/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0325\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.02879\n",
            "Epoch 16/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0303\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.02879\n",
            "Epoch 17/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0369\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.02879\n",
            "Epoch 18/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0298\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.02879\n",
            "Epoch 19/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0320\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.02879\n",
            "Epoch 20/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.0315\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.02879\n",
            "Epoch 21/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0334\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.02879\n",
            "Epoch 22/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0301\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.02879\n",
            "Epoch 23/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0311\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.02879\n",
            "Epoch 24/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0342\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.02879\n",
            "Epoch 25/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0328\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.02879\n",
            "Epoch 26/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0347\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.02879\n",
            "Epoch 27/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0308\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.02879\n",
            "Epoch 28/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0308\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.02879\n",
            "Epoch 29/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0344\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.02879\n",
            "Epoch 30/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.0363\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.02879\n",
            "Epoch 31/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.0309\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.02879\n",
            "Epoch 32/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0319 - val_loss: 0.0321\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.02879\n",
            "Epoch 33/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0333\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.02879\n",
            "Epoch 34/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0356\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.02879\n",
            "Epoch 35/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0293\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.02879\n",
            "Epoch 36/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0306\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.02879\n",
            "Epoch 37/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0318\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.02879\n",
            "Epoch 38/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.0359\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.02879\n",
            "Epoch 39/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0310\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.02879\n",
            "Epoch 40/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0356\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.02879\n",
            "Epoch 41/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.0321 - val_loss: 0.0325\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.02879\n",
            "Epoch 42/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.0341\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.02879\n",
            "Epoch 43/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0316\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.02879\n",
            "Epoch 44/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0329\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.02879\n",
            "Epoch 45/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0352\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.02879\n",
            "Epoch 46/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0326\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.02879\n",
            "Epoch 47/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0318\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.02879\n",
            "Epoch 48/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0318\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.02879\n",
            "Epoch 49/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0349\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.02879\n",
            "Epoch 50/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0328\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.02879\n",
            "Epoch 51/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.0341\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.02879\n",
            "Epoch 52/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0310\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.02879\n",
            "Epoch 53/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0310\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.02879\n",
            "Epoch 54/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0318\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.02879\n",
            "Epoch 55/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0346\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.02879\n",
            "Epoch 56/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0325\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.02879\n",
            "Epoch 57/200\n",
            "93/93 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0338\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.02879\n",
            "Epoch 58/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0331\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.02879\n",
            "Epoch 59/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0330\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.02879\n",
            "Epoch 60/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0313\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.02879\n",
            "Epoch 61/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0361\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.02879\n",
            "Epoch 62/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0320\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.02879\n",
            "Epoch 63/200\n",
            "93/93 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0322\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.02879\n",
            "Epoch 64/200\n",
            "29/93 [========>.....................] - ETA: 0s - loss: 0.0209"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL5Wr_NkdsN0"
      },
      "source": [
        "def grafikon(fx,ind,desc1,txt1,desc2=\"\",txt2=\"\",desc3=\"\",txt3=\"\",ngraf=2,c1='rgba(35,128,132,0.8)', c2='rgba(193,99,99,0.8)',c3='rgba(193,99,0,0.8)',title=None):\n",
        "    '''\n",
        "    fx: dataFrame\n",
        "    ind: index\n",
        "    desc1:column1\n",
        "    txt1: label1\n",
        "    desc2:column2\n",
        "    txt2: label2\n",
        "    ngraf: number of graph\n",
        "    c1: color1\n",
        "    c2: color2\n",
        "    title: graph title\n",
        "    '''\n",
        "    \n",
        "    #x_=[i for i in range(len(y_pred))]\n",
        "    if title==None:\n",
        "      title=txt1+txt2\n",
        "    import plotly.express as px\n",
        "    import plotly.graph_objects as go\n",
        "    from plotly.subplots import make_subplots\n",
        "    fig0 = make_subplots(rows=1, cols=1)\n",
        "    \n",
        "    if True:\n",
        "        fig0.add_trace(\n",
        "            go.Scatter(x=fx[ind], y=fx[desc1], name=txt1, line=dict(color=c1) ,showlegend=True  ),\n",
        "\n",
        "            row=1, col=1\n",
        "\n",
        "        )\n",
        "    \n",
        "    if ngraf>1:\n",
        "        fig0.add_trace(\n",
        "            go.Scatter(x=fx[ind], y=fx[desc2], name=txt2, line=dict(color=c2) ,showlegend=True  ),\n",
        "\n",
        "            row=1, col=1\n",
        "        )\n",
        "    if ngraf>2:\n",
        "        fig0.add_trace(\n",
        "            go.Scatter(x=fx[ind], y=fx[desc3], name=txt3, line=dict(color=c3) ,showlegend=True  ),\n",
        "\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    fig0.update_layout(\n",
        "        title=title,\n",
        "        autosize=False,\n",
        "        width=1200,\n",
        "        height=600,\n",
        "        \n",
        "        )\n",
        "\n",
        "    fig0.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FAjyiKgpoij"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QCA3rvVGLXL"
      },
      "source": [
        "model_loaded=model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdlFfbUiWvra"
      },
      "source": [
        "y_pred=model_loaded.predict(XSJ_scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdZLGOUfXGpi"
      },
      "source": [
        "y_pred[1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck4uVgpwJzLH"
      },
      "source": [
        "def backtest(index):\n",
        "    y_orig=ySJ_scale\n",
        "    output=pd.DataFrame(y_pred)\n",
        "    output[\"a\"]=y_orig\n",
        "    output.columns=[\"pred\",\"orig\"]\n",
        "    output[\"index\"]=range(0,len(y_orig))\n",
        "    grafikon(output,\"index\",\"orig\",\"orig\",\"pred\",\"pred\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnlcf3ie3Mav"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQpwk-qY7j5Y"
      },
      "source": [
        "backtest(5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}