{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dengue_neural_01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNoWgIVrvi1LxehoA0q1z8H",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sipocz/_dengue/blob/main/dengue_neural_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0whmKbt9DSbQ"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#--------------scikit import \n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGsL2vrsC0rU",
        "outputId": "0400213c-eee4-4ba7-d7cb-7394aaf78842"
      },
      "source": [
        "#_Dengue\n",
        "_project=\"_dengue\"\n",
        "_PCVERSION_=False\n",
        "_GITHUBVERSION_=True\n",
        "_GOOGLEVERSION_=False\n",
        "if _PCVERSION_:\n",
        "    basedir=\"C:/Users/sipocz/OneDrive/Dokumentumok/GitHub\"\n",
        "\n",
        "if _GOOGLEVERSION_:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive',force_remount=True)\n",
        "    basedir=\"/content/drive/My Drive/001_AI\"\n",
        "\n",
        "if _GITHUBVERSION_:\n",
        "    !mkdir _dengue\n",
        "    files=[\"dengue_features_train.csv\",\"dengue_labels_train.csv\",\"dengue_features_test.csv\",\"/models/'model___79_0.04485_0.02581_.hdf5'\"]\n",
        "    path=\"https://raw.githubusercontent.com/sipocz/_dengue/main/\"\n",
        "    basedir=\"./\"\n",
        "    storeto=basedir+_project\n",
        "    for f in files:\n",
        "        fname=path+f\n",
        "        !rm $f\n",
        "        !wget $fname\n",
        "        !mv $f $storeto"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'dengue_features_train.csv': No such file or directory\n",
            "--2021-08-12 21:36:11--  https://raw.githubusercontent.com/sipocz/_dengue/main/dengue_features_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 287139 (280K) [text/plain]\n",
            "Saving to: ‘dengue_features_train.csv’\n",
            "\n",
            "dengue_features_tra 100%[===================>] 280.41K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-08-12 21:36:12 (12.6 MB/s) - ‘dengue_features_train.csv’ saved [287139/287139]\n",
            "\n",
            "rm: cannot remove 'dengue_labels_train.csv': No such file or directory\n",
            "--2021-08-12 21:36:12--  https://raw.githubusercontent.com/sipocz/_dengue/main/dengue_labels_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19582 (19K) [text/plain]\n",
            "Saving to: ‘dengue_labels_train.csv’\n",
            "\n",
            "dengue_labels_train 100%[===================>]  19.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-12 21:36:12 (100 MB/s) - ‘dengue_labels_train.csv’ saved [19582/19582]\n",
            "\n",
            "rm: cannot remove 'dengue_features_test.csv': No such file or directory\n",
            "--2021-08-12 21:36:13--  https://raw.githubusercontent.com/sipocz/_dengue/main/dengue_features_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82465 (81K) [text/plain]\n",
            "Saving to: ‘dengue_features_test.csv’\n",
            "\n",
            "dengue_features_tes 100%[===================>]  80.53K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2021-08-12 21:36:13 (8.62 MB/s) - ‘dengue_features_test.csv’ saved [82465/82465]\n",
            "\n",
            "rm: cannot remove '/models/model___79_0.04485_0.02581_.hdf5': No such file or directory\n",
            "--2021-08-12 21:36:13--  https://raw.githubusercontent.com/sipocz/_dengue/main//models/model___79_0.04485_0.02581_.hdf5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sipocz/_dengue/main/models/model___79_0.04485_0.02581_.hdf5 [following]\n",
            "--2021-08-12 21:36:13--  https://raw.githubusercontent.com/sipocz/_dengue/main/models/model___79_0.04485_0.02581_.hdf5\n",
            "Reusing existing connection to raw.githubusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 386732 (378K) [application/octet-stream]\n",
            "Saving to: ‘model___79_0.04485_0.02581_.hdf5’\n",
            "\n",
            "model___79_0.04485_ 100%[===================>] 377.67K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-08-12 21:36:13 (14.7 MB/s) - ‘model___79_0.04485_0.02581_.hdf5’ saved [386732/386732]\n",
            "\n",
            "mv: cannot stat '/models/model___79_0.04485_0.02581_.hdf5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eptb9-bvDGXL"
      },
      "source": [
        "\n",
        "features_train=basedir+_project+\"/\"+\"dengue_features_train.csv\"\n",
        "labels_train=basedir+_project+\"/\"+\"dengue_labels_train.csv\"\n",
        "features_test=basedir+_project+\"/\"+\"dengue_features_test.csv\"\n",
        "\n",
        "\n",
        "X_train=pd.read_csv(features_train)\n",
        "y_train=pd.read_csv(labels_train)\n",
        "X_test=pd.read_csv(features_test)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRYy2LdXria_"
      },
      "source": [
        "X_train[\"total_cases\"]=y_train[\"total_cases\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24pyp2CPDZ8u"
      },
      "source": [
        "X_test.fillna(method=\"bfill\", inplace=True)\n",
        "X_train.fillna(method=\"bfill\", inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhcMI8ZeTx69"
      },
      "source": [
        "\n",
        "X_train_sj=X_train[X_train.city == \"sj\"]\n",
        "X_train_iq=X_train[X_train.city == \"iq\"]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z2gUXspSzAi"
      },
      "source": [
        "\n",
        "X_test_sj=X_test[X_test.city == \"sj\"]\n",
        "X_test_iq=X_test[X_test.city == \"iq\"]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV9fDqjQNKzr"
      },
      "source": [
        "def build_training_data(dataset,labelset, history_size = 5, target_size = 23):\n",
        "    '''\n",
        "    source: https://www.mikulskibartosz.name/how-to-split-a-data-frame-into-time-series-for-lstm-deep-neural-network/\n",
        "    '''\n",
        "    start_index = history_size\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for i in range(start_index, end_index):\n",
        "        indices = range(i - history_size, i, 1)\n",
        "        #print(indices)\n",
        "        row=[]\n",
        "        for j in indices:\n",
        "            row=row+list(dataset.iloc[j])\n",
        "        data.append(row)\n",
        "\n",
        "    #label \n",
        "    for i in range(start_index, end_index):\n",
        "        indices = range(i, i+target_size, 1)\n",
        "        #print(indices)\n",
        "        row=[]\n",
        "        for j in indices:\n",
        "            row=row+list(labelset.iloc[j])\n",
        "        labels.append(row)\n",
        "\n",
        "\n",
        "    data = np.array(data)\n",
        "    labels=np.array(labels)\n",
        "    #data = data.reshape((-1, 1))\n",
        "    return data, labels\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z1tYJIoDbe-"
      },
      "source": [
        "def datapipe_Xy(Xinp,yinp):\n",
        "    X=Xinp.copy(deep=True)\n",
        "    y=yinp.copy(deep=True)\n",
        "    prediktorok=['ndvi_ne', 'ndvi_nw',\n",
        "       'ndvi_se', 'ndvi_sw',\n",
        "       'precipitation_amt_mm', 'reanalysis_air_temp_k',\n",
        "       'reanalysis_avg_temp_k', 'reanalysis_dew_point_temp_k',\n",
        "       'reanalysis_max_air_temp_k', 'reanalysis_min_air_temp_k',\n",
        "       'reanalysis_precip_amt_kg_per_m2',\n",
        "       'reanalysis_relative_humidity_percent', 'reanalysis_sat_precip_amt_mm',\n",
        "       'reanalysis_specific_humidity_g_per_kg', 'reanalysis_tdtr_k',\n",
        "       'station_avg_temp_c', 'station_diur_temp_rng_c', 'station_max_temp_c',\n",
        "       'station_min_temp_c', 'station_precip_mm']\n",
        "    X[\"reanalysis_air_temp_k\"]=X[\"reanalysis_air_temp_k\"]-273.15\n",
        "    X[\"reanalysis_avg_temp_k\"]=X[\"reanalysis_avg_temp_k\"]-273.15\n",
        "    X['reanalysis_max_air_temp_k']=X['reanalysis_max_air_temp_k']-273.15\n",
        "    X[\"reanalysis_min_air_temp_k\"]=X[\"reanalysis_min_air_temp_k\"]-273.15\n",
        "    X[\"reanalysis_dew_point_temp_k\"]=X[\"reanalysis_dew_point_temp_k\"]-273.15\n",
        "    X[\"ndvi_N\"]=(X[\"ndvi_ne\"]+X[\"ndvi_nw\"])/2\n",
        "    X[\"ndvi_S\"]=(X[\"ndvi_se\"]+X[\"ndvi_sw\"])/2\n",
        "\n",
        "\n",
        "    Xprediktor=['ndvi_N','ndvi_S',\n",
        "       'precipitation_amt_mm', 'reanalysis_air_temp_k',\n",
        "       'reanalysis_avg_temp_k', 'reanalysis_dew_point_temp_k',\n",
        "       'reanalysis_max_air_temp_k', 'reanalysis_min_air_temp_k',\n",
        "       'reanalysis_precip_amt_kg_per_m2',\n",
        "       'reanalysis_relative_humidity_percent', 'reanalysis_sat_precip_amt_mm',\n",
        "       'reanalysis_specific_humidity_g_per_kg', 'reanalysis_tdtr_k',\n",
        "       'station_avg_temp_c', 'station_diur_temp_rng_c', 'station_max_temp_c',\n",
        "       'station_min_temp_c', 'station_precip_mm']\n",
        "    \n",
        "    yprediktor=[\"total_cases\"]\n",
        "    \n",
        "    return(X[Xprediktor],y[yprediktor])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5wV38Y_Nwj6"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5weMYMnL0Ts"
      },
      "source": [
        "#test\n",
        "X2,y2=datapipe_Xy(X_train_sj,X_train_sj)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "o3NdSvd9Nxaq",
        "outputId": "9b0e0bf5-3058-4515-87c4-371e6999cf7f"
      },
      "source": [
        "y2.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_cases</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   total_cases\n",
              "0            4\n",
              "1            5\n",
              "2            4\n",
              "3            3\n",
              "4            6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "scTNFd-XLVBv",
        "outputId": "9a5be544-fab5-491d-ca6e-f78d4084ee3c"
      },
      "source": [
        "X2.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ndvi_N</th>\n",
              "      <th>ndvi_S</th>\n",
              "      <th>precipitation_amt_mm</th>\n",
              "      <th>reanalysis_air_temp_k</th>\n",
              "      <th>reanalysis_avg_temp_k</th>\n",
              "      <th>reanalysis_dew_point_temp_k</th>\n",
              "      <th>reanalysis_max_air_temp_k</th>\n",
              "      <th>reanalysis_min_air_temp_k</th>\n",
              "      <th>reanalysis_precip_amt_kg_per_m2</th>\n",
              "      <th>reanalysis_relative_humidity_percent</th>\n",
              "      <th>reanalysis_sat_precip_amt_mm</th>\n",
              "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
              "      <th>reanalysis_tdtr_k</th>\n",
              "      <th>station_avg_temp_c</th>\n",
              "      <th>station_diur_temp_rng_c</th>\n",
              "      <th>station_max_temp_c</th>\n",
              "      <th>station_min_temp_c</th>\n",
              "      <th>station_precip_mm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.113162</td>\n",
              "      <td>0.188050</td>\n",
              "      <td>12.42</td>\n",
              "      <td>24.422857</td>\n",
              "      <td>24.592857</td>\n",
              "      <td>19.264286</td>\n",
              "      <td>26.65</td>\n",
              "      <td>22.75</td>\n",
              "      <td>32.00</td>\n",
              "      <td>73.365714</td>\n",
              "      <td>12.42</td>\n",
              "      <td>14.012857</td>\n",
              "      <td>2.628571</td>\n",
              "      <td>25.442857</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>29.4</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.156037</td>\n",
              "      <td>0.158921</td>\n",
              "      <td>22.82</td>\n",
              "      <td>25.061429</td>\n",
              "      <td>25.292857</td>\n",
              "      <td>20.801429</td>\n",
              "      <td>27.75</td>\n",
              "      <td>23.25</td>\n",
              "      <td>17.94</td>\n",
              "      <td>77.368571</td>\n",
              "      <td>22.82</td>\n",
              "      <td>15.372857</td>\n",
              "      <td>2.371429</td>\n",
              "      <td>26.714286</td>\n",
              "      <td>6.371429</td>\n",
              "      <td>31.7</td>\n",
              "      <td>22.2</td>\n",
              "      <td>8.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.102608</td>\n",
              "      <td>0.164021</td>\n",
              "      <td>34.54</td>\n",
              "      <td>25.631429</td>\n",
              "      <td>25.728571</td>\n",
              "      <td>22.284286</td>\n",
              "      <td>27.35</td>\n",
              "      <td>24.15</td>\n",
              "      <td>26.10</td>\n",
              "      <td>82.052857</td>\n",
              "      <td>34.54</td>\n",
              "      <td>16.848571</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>26.714286</td>\n",
              "      <td>6.485714</td>\n",
              "      <td>32.2</td>\n",
              "      <td>22.8</td>\n",
              "      <td>41.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.186850</td>\n",
              "      <td>0.231721</td>\n",
              "      <td>15.36</td>\n",
              "      <td>25.837143</td>\n",
              "      <td>26.078571</td>\n",
              "      <td>22.160000</td>\n",
              "      <td>28.25</td>\n",
              "      <td>23.85</td>\n",
              "      <td>13.90</td>\n",
              "      <td>80.337143</td>\n",
              "      <td>15.36</td>\n",
              "      <td>16.672857</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>27.471429</td>\n",
              "      <td>6.771429</td>\n",
              "      <td>33.3</td>\n",
              "      <td>23.3</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.229200</td>\n",
              "      <td>0.249270</td>\n",
              "      <td>7.52</td>\n",
              "      <td>26.368571</td>\n",
              "      <td>26.514286</td>\n",
              "      <td>22.671429</td>\n",
              "      <td>28.75</td>\n",
              "      <td>24.35</td>\n",
              "      <td>12.20</td>\n",
              "      <td>80.460000</td>\n",
              "      <td>7.52</td>\n",
              "      <td>17.210000</td>\n",
              "      <td>3.014286</td>\n",
              "      <td>28.942857</td>\n",
              "      <td>9.371429</td>\n",
              "      <td>35.0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>5.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ndvi_N    ndvi_S  ...  station_min_temp_c  station_precip_mm\n",
              "0  0.113162  0.188050  ...                20.0               16.0\n",
              "1  0.156037  0.158921  ...                22.2                8.6\n",
              "2  0.102608  0.164021  ...                22.8               41.4\n",
              "3  0.186850  0.231721  ...                23.3                4.0\n",
              "4  0.229200  0.249270  ...                23.9                5.8\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI4PcCj8kDf2"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATkEEguEb6W6"
      },
      "source": [
        "XSJ,ySJ=build_training_data(X2,y2,4,1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlgmt1SvcCj2",
        "outputId": "c17de480-0e5d-457f-d574-17c313ef2644"
      },
      "source": [
        "len(XSJ)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRDYJ9lQjOX5",
        "outputId": "55206894-1c7d-4703-fbf1-7cfdd8053e7e"
      },
      "source": [
        "ySJ[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD-sOBFYmbkG"
      },
      "source": [
        "from keras.backend import clear_session\n",
        "from keras.layers import InputLayer, Dense, LSTM, Input, Dropout,Flatten,Bidirectional\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import SGD,Adam,Adamax,Nadam,Ftrl,Adadelta,Adagrad,Nadam,RMSprop\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.backend import clear_session\n",
        "from tensorflow.keras.losses import mean_absolute_percentage_error, huber,kld\n",
        "#import tensorflow_addons as tfa"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3ebXumcmtjE",
        "outputId": "34fdd62d-94a0-4029-ac68-191b5004f4cb"
      },
      "source": [
        "clear_session() \n",
        "dropout_1_rate=0.15\n",
        "input_size=len(XSJ[0]) # timesteps\n",
        "output_size=len(ySJ[0]) # features\n",
        "learning_rate=0.00001\n",
        "\n",
        "inputs=Input(shape=(input_size))\n",
        "o1=Dense(500,activation=\"relu\",)(inputs)\n",
        "d1=Dropout(dropout_1_rate)(o1)\n",
        "o2=Dense(2000,activation=\"relu\",)(d1)\n",
        "d2=Dropout(dropout_1_rate)(o2)\n",
        "\n",
        "o3=Dense(1000,activation=\"relu\",)(d2)\n",
        "d3=Dropout(dropout_1_rate)(o3)\n",
        "\n",
        "result=Dense(output_size,activation=\"sigmoid\",)(d3)\n",
        "#dropout1=Dropout(rate=dropout_1_rate)(layer2)\n",
        "#result=Dense(output_size,activation=\"sigmoid\")(dropout1)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=result)\n",
        "model.compile(optimizer=Adamax(learning_rate=learning_rate), loss=\"mse\")  #RMSprop\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 72)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               36500     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2000)              1002000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              2001000   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 1001      \n",
            "=================================================================\n",
            "Total params: 3,040,501\n",
            "Trainable params: 3,040,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmoQ0-8Incy8"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6h8N5NrpbwH"
      },
      "source": [
        "\n",
        "x_scaler = MinMaxScaler()\n",
        "XSJ_scale = pd.DataFrame(x_scaler.fit_transform(XSJ))\n",
        "\n",
        "y_scaler=MinMaxScaler(feature_range=(0,1))\n",
        "ySJ_scale=pd.DataFrame(y_scaler.fit_transform(ySJ))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "EZ6f8mr5w5uV",
        "outputId": "d24eae7f-7d54-43d8-adf3-408e3c4a5520"
      },
      "source": [
        "ySJ_scale"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.004338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.008677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.010846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.021692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>0.006508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>0.008677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>0.006508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>0.002169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>0.006508</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>931 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0\n",
              "0    0.013015\n",
              "1    0.004338\n",
              "2    0.008677\n",
              "3    0.010846\n",
              "4    0.021692\n",
              "..        ...\n",
              "926  0.006508\n",
              "927  0.008677\n",
              "928  0.006508\n",
              "929  0.002169\n",
              "930  0.006508\n",
              "\n",
              "[931 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXBjot_lP3Mv"
      },
      "source": [
        "!rm model*"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q5ghx0VORBA"
      },
      "source": [
        "fname=\"./model__\"\n",
        "callbacks = [#callback_LR,\n",
        "       \n",
        "        ModelCheckpoint(filepath=fname+\"_{epoch}\"+\"_{loss:.5f}_{val_loss:.5f}_.hdf5\", monitor='val_loss',\n",
        "                        verbose=2, save_best_only=True, mode='min',)]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "WYy19t3r0255",
        "outputId": "7e0e5fd3-7d0c-4b23-f41e-10fa5328a13a"
      },
      "source": [
        "XSJ_scale"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.578732</td>\n",
              "      <td>0.506411</td>\n",
              "      <td>0.031797</td>\n",
              "      <td>0.261008</td>\n",
              "      <td>0.269185</td>\n",
              "      <td>0.339933</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.452055</td>\n",
              "      <td>0.056091</td>\n",
              "      <td>0.318138</td>\n",
              "      <td>0.031797</td>\n",
              "      <td>0.297392</td>\n",
              "      <td>0.413953</td>\n",
              "      <td>0.359684</td>\n",
              "      <td>0.440318</td>\n",
              "      <td>0.303371</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.052305</td>\n",
              "      <td>0.637045</td>\n",
              "      <td>0.431714</td>\n",
              "      <td>0.058423</td>\n",
              "      <td>0.362993</td>\n",
              "      <td>0.384888</td>\n",
              "      <td>0.528474</td>\n",
              "      <td>0.476923</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.031446</td>\n",
              "      <td>0.510214</td>\n",
              "      <td>0.058423</td>\n",
              "      <td>0.473460</td>\n",
              "      <td>0.330233</td>\n",
              "      <td>0.535573</td>\n",
              "      <td>0.342175</td>\n",
              "      <td>0.561798</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.028114</td>\n",
              "      <td>0.564377</td>\n",
              "      <td>0.444793</td>\n",
              "      <td>0.088428</td>\n",
              "      <td>0.454027</td>\n",
              "      <td>0.456907</td>\n",
              "      <td>0.710356</td>\n",
              "      <td>0.415385</td>\n",
              "      <td>0.643836</td>\n",
              "      <td>0.045749</td>\n",
              "      <td>0.734988</td>\n",
              "      <td>0.088428</td>\n",
              "      <td>0.664509</td>\n",
              "      <td>0.306977</td>\n",
              "      <td>0.535573</td>\n",
              "      <td>0.363395</td>\n",
              "      <td>0.617978</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.135338</td>\n",
              "      <td>0.678953</td>\n",
              "      <td>0.618401</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.486881</td>\n",
              "      <td>0.514758</td>\n",
              "      <td>0.695111</td>\n",
              "      <td>0.553846</td>\n",
              "      <td>0.602740</td>\n",
              "      <td>0.024365</td>\n",
              "      <td>0.652660</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.641761</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.640316</td>\n",
              "      <td>0.416446</td>\n",
              "      <td>0.741573</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.013076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.637045</td>\n",
              "      <td>0.431714</td>\n",
              "      <td>0.058423</td>\n",
              "      <td>0.362993</td>\n",
              "      <td>0.384888</td>\n",
              "      <td>0.528474</td>\n",
              "      <td>0.476923</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.031446</td>\n",
              "      <td>0.510214</td>\n",
              "      <td>0.058423</td>\n",
              "      <td>0.473460</td>\n",
              "      <td>0.330233</td>\n",
              "      <td>0.535573</td>\n",
              "      <td>0.342175</td>\n",
              "      <td>0.561798</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.028114</td>\n",
              "      <td>0.564377</td>\n",
              "      <td>0.444793</td>\n",
              "      <td>0.088428</td>\n",
              "      <td>0.454027</td>\n",
              "      <td>0.456907</td>\n",
              "      <td>0.710356</td>\n",
              "      <td>0.415385</td>\n",
              "      <td>0.643836</td>\n",
              "      <td>0.045749</td>\n",
              "      <td>0.734988</td>\n",
              "      <td>0.088428</td>\n",
              "      <td>0.664509</td>\n",
              "      <td>0.306977</td>\n",
              "      <td>0.535573</td>\n",
              "      <td>0.363395</td>\n",
              "      <td>0.617978</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.135338</td>\n",
              "      <td>0.678953</td>\n",
              "      <td>0.618401</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.486881</td>\n",
              "      <td>0.514758</td>\n",
              "      <td>0.695111</td>\n",
              "      <td>0.553846</td>\n",
              "      <td>0.602740</td>\n",
              "      <td>0.024365</td>\n",
              "      <td>0.652660</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.641761</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.640316</td>\n",
              "      <td>0.416446</td>\n",
              "      <td>0.741573</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.013076</td>\n",
              "      <td>0.736552</td>\n",
              "      <td>0.663403</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.571755</td>\n",
              "      <td>0.586777</td>\n",
              "      <td>0.757841</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.671233</td>\n",
              "      <td>0.021385</td>\n",
              "      <td>0.658555</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.711300</td>\n",
              "      <td>0.539535</td>\n",
              "      <td>0.843874</td>\n",
              "      <td>0.899204</td>\n",
              "      <td>0.932584</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.018960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.564377</td>\n",
              "      <td>0.444793</td>\n",
              "      <td>0.088428</td>\n",
              "      <td>0.454027</td>\n",
              "      <td>0.456907</td>\n",
              "      <td>0.710356</td>\n",
              "      <td>0.415385</td>\n",
              "      <td>0.643836</td>\n",
              "      <td>0.045749</td>\n",
              "      <td>0.734988</td>\n",
              "      <td>0.088428</td>\n",
              "      <td>0.664509</td>\n",
              "      <td>0.306977</td>\n",
              "      <td>0.535573</td>\n",
              "      <td>0.363395</td>\n",
              "      <td>0.617978</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.135338</td>\n",
              "      <td>0.678953</td>\n",
              "      <td>0.618401</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.486881</td>\n",
              "      <td>0.514758</td>\n",
              "      <td>0.695111</td>\n",
              "      <td>0.553846</td>\n",
              "      <td>0.602740</td>\n",
              "      <td>0.024365</td>\n",
              "      <td>0.652660</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.641761</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.640316</td>\n",
              "      <td>0.416446</td>\n",
              "      <td>0.741573</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.013076</td>\n",
              "      <td>0.736552</td>\n",
              "      <td>0.663403</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.571755</td>\n",
              "      <td>0.586777</td>\n",
              "      <td>0.757841</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.671233</td>\n",
              "      <td>0.021385</td>\n",
              "      <td>0.658555</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.711300</td>\n",
              "      <td>0.539535</td>\n",
              "      <td>0.843874</td>\n",
              "      <td>0.899204</td>\n",
              "      <td>0.932584</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.018960</td>\n",
              "      <td>0.620503</td>\n",
              "      <td>0.583288</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.589551</td>\n",
              "      <td>0.603306</td>\n",
              "      <td>0.761521</td>\n",
              "      <td>0.707692</td>\n",
              "      <td>0.753425</td>\n",
              "      <td>0.046433</td>\n",
              "      <td>0.631272</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.711670</td>\n",
              "      <td>0.241860</td>\n",
              "      <td>0.729249</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.865169</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.127820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.678953</td>\n",
              "      <td>0.618401</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.486881</td>\n",
              "      <td>0.514758</td>\n",
              "      <td>0.695111</td>\n",
              "      <td>0.553846</td>\n",
              "      <td>0.602740</td>\n",
              "      <td>0.024365</td>\n",
              "      <td>0.652660</td>\n",
              "      <td>0.039324</td>\n",
              "      <td>0.641761</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.640316</td>\n",
              "      <td>0.416446</td>\n",
              "      <td>0.741573</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.013076</td>\n",
              "      <td>0.736552</td>\n",
              "      <td>0.663403</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.571755</td>\n",
              "      <td>0.586777</td>\n",
              "      <td>0.757841</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.671233</td>\n",
              "      <td>0.021385</td>\n",
              "      <td>0.658555</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.711300</td>\n",
              "      <td>0.539535</td>\n",
              "      <td>0.843874</td>\n",
              "      <td>0.899204</td>\n",
              "      <td>0.932584</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.018960</td>\n",
              "      <td>0.620503</td>\n",
              "      <td>0.583288</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.589551</td>\n",
              "      <td>0.603306</td>\n",
              "      <td>0.761521</td>\n",
              "      <td>0.707692</td>\n",
              "      <td>0.753425</td>\n",
              "      <td>0.046433</td>\n",
              "      <td>0.631272</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.711670</td>\n",
              "      <td>0.241860</td>\n",
              "      <td>0.729249</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.865169</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.127820</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.556728</td>\n",
              "      <td>0.008909</td>\n",
              "      <td>0.522017</td>\n",
              "      <td>0.513577</td>\n",
              "      <td>0.763273</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.698630</td>\n",
              "      <td>0.067660</td>\n",
              "      <td>0.732451</td>\n",
              "      <td>0.008909</td>\n",
              "      <td>0.714444</td>\n",
              "      <td>0.223256</td>\n",
              "      <td>0.632411</td>\n",
              "      <td>0.416446</td>\n",
              "      <td>0.617978</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.097091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.736552</td>\n",
              "      <td>0.663403</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.571755</td>\n",
              "      <td>0.586777</td>\n",
              "      <td>0.757841</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.671233</td>\n",
              "      <td>0.021385</td>\n",
              "      <td>0.658555</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.711300</td>\n",
              "      <td>0.539535</td>\n",
              "      <td>0.843874</td>\n",
              "      <td>0.899204</td>\n",
              "      <td>0.932584</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.018960</td>\n",
              "      <td>0.620503</td>\n",
              "      <td>0.583288</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.589551</td>\n",
              "      <td>0.603306</td>\n",
              "      <td>0.761521</td>\n",
              "      <td>0.707692</td>\n",
              "      <td>0.753425</td>\n",
              "      <td>0.046433</td>\n",
              "      <td>0.631272</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.711670</td>\n",
              "      <td>0.241860</td>\n",
              "      <td>0.729249</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.865169</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.127820</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.556728</td>\n",
              "      <td>0.008909</td>\n",
              "      <td>0.522017</td>\n",
              "      <td>0.513577</td>\n",
              "      <td>0.763273</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.698630</td>\n",
              "      <td>0.067660</td>\n",
              "      <td>0.732451</td>\n",
              "      <td>0.008909</td>\n",
              "      <td>0.714444</td>\n",
              "      <td>0.223256</td>\n",
              "      <td>0.632411</td>\n",
              "      <td>0.416446</td>\n",
              "      <td>0.617978</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.097091</td>\n",
              "      <td>0.523427</td>\n",
              "      <td>0.388962</td>\n",
              "      <td>0.386892</td>\n",
              "      <td>0.583390</td>\n",
              "      <td>0.564345</td>\n",
              "      <td>0.844927</td>\n",
              "      <td>0.430769</td>\n",
              "      <td>0.794521</td>\n",
              "      <td>0.052585</td>\n",
              "      <td>0.798464</td>\n",
              "      <td>0.386892</td>\n",
              "      <td>0.810616</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>0.764822</td>\n",
              "      <td>0.586207</td>\n",
              "      <td>0.808989</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.068977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>926</th>\n",
              "      <td>0.265885</td>\n",
              "      <td>0.632176</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.314397</td>\n",
              "      <td>0.321133</td>\n",
              "      <td>0.428246</td>\n",
              "      <td>0.276923</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.014549</td>\n",
              "      <td>0.386276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.365452</td>\n",
              "      <td>0.172093</td>\n",
              "      <td>0.284585</td>\n",
              "      <td>0.233422</td>\n",
              "      <td>0.179775</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.374852</td>\n",
              "      <td>0.445983</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291809</td>\n",
              "      <td>0.323495</td>\n",
              "      <td>0.350797</td>\n",
              "      <td>0.323077</td>\n",
              "      <td>0.506849</td>\n",
              "      <td>0.011323</td>\n",
              "      <td>0.284275</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291474</td>\n",
              "      <td>0.302326</td>\n",
              "      <td>0.262846</td>\n",
              "      <td>0.180371</td>\n",
              "      <td>0.123596</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.042171</td>\n",
              "      <td>0.303140</td>\n",
              "      <td>0.508115</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.309833</td>\n",
              "      <td>0.312869</td>\n",
              "      <td>0.418258</td>\n",
              "      <td>0.323077</td>\n",
              "      <td>0.397260</td>\n",
              "      <td>0.011394</td>\n",
              "      <td>0.381272</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.357130</td>\n",
              "      <td>0.409302</td>\n",
              "      <td>0.314229</td>\n",
              "      <td>0.294430</td>\n",
              "      <td>0.303371</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.042498</td>\n",
              "      <td>0.110235</td>\n",
              "      <td>0.346851</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264659</td>\n",
              "      <td>0.252656</td>\n",
              "      <td>0.313299</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.479452</td>\n",
              "      <td>0.016442</td>\n",
              "      <td>0.249452</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259663</td>\n",
              "      <td>0.237209</td>\n",
              "      <td>0.343874</td>\n",
              "      <td>0.238727</td>\n",
              "      <td>0.247191</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.014384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>0.374852</td>\n",
              "      <td>0.445983</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291809</td>\n",
              "      <td>0.323495</td>\n",
              "      <td>0.350797</td>\n",
              "      <td>0.323077</td>\n",
              "      <td>0.506849</td>\n",
              "      <td>0.011323</td>\n",
              "      <td>0.284275</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291474</td>\n",
              "      <td>0.302326</td>\n",
              "      <td>0.262846</td>\n",
              "      <td>0.180371</td>\n",
              "      <td>0.123596</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.042171</td>\n",
              "      <td>0.303140</td>\n",
              "      <td>0.508115</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.309833</td>\n",
              "      <td>0.312869</td>\n",
              "      <td>0.418258</td>\n",
              "      <td>0.323077</td>\n",
              "      <td>0.397260</td>\n",
              "      <td>0.011394</td>\n",
              "      <td>0.381272</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.357130</td>\n",
              "      <td>0.409302</td>\n",
              "      <td>0.314229</td>\n",
              "      <td>0.294430</td>\n",
              "      <td>0.303371</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.042498</td>\n",
              "      <td>0.110235</td>\n",
              "      <td>0.346851</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264659</td>\n",
              "      <td>0.252656</td>\n",
              "      <td>0.313299</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.479452</td>\n",
              "      <td>0.016442</td>\n",
              "      <td>0.249452</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259663</td>\n",
              "      <td>0.237209</td>\n",
              "      <td>0.343874</td>\n",
              "      <td>0.238727</td>\n",
              "      <td>0.247191</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.014384</td>\n",
              "      <td>0.471982</td>\n",
              "      <td>0.267319</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234086</td>\n",
              "      <td>0.218418</td>\n",
              "      <td>0.314351</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.315068</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.296545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261698</td>\n",
              "      <td>0.818605</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.466844</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.001635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>0.303140</td>\n",
              "      <td>0.508115</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.309833</td>\n",
              "      <td>0.312869</td>\n",
              "      <td>0.418258</td>\n",
              "      <td>0.323077</td>\n",
              "      <td>0.397260</td>\n",
              "      <td>0.011394</td>\n",
              "      <td>0.381272</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.357130</td>\n",
              "      <td>0.409302</td>\n",
              "      <td>0.314229</td>\n",
              "      <td>0.294430</td>\n",
              "      <td>0.303371</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.042498</td>\n",
              "      <td>0.110235</td>\n",
              "      <td>0.346851</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264659</td>\n",
              "      <td>0.252656</td>\n",
              "      <td>0.313299</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.479452</td>\n",
              "      <td>0.016442</td>\n",
              "      <td>0.249452</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259663</td>\n",
              "      <td>0.237209</td>\n",
              "      <td>0.343874</td>\n",
              "      <td>0.238727</td>\n",
              "      <td>0.247191</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.014384</td>\n",
              "      <td>0.471982</td>\n",
              "      <td>0.267319</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234086</td>\n",
              "      <td>0.218418</td>\n",
              "      <td>0.314351</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.315068</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.296545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261698</td>\n",
              "      <td>0.818605</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.466844</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.001635</td>\n",
              "      <td>0.450629</td>\n",
              "      <td>0.802103</td>\n",
              "      <td>0.069611</td>\n",
              "      <td>0.162902</td>\n",
              "      <td>0.139315</td>\n",
              "      <td>0.300859</td>\n",
              "      <td>0.292308</td>\n",
              "      <td>0.246575</td>\n",
              "      <td>0.013234</td>\n",
              "      <td>0.360433</td>\n",
              "      <td>0.069611</td>\n",
              "      <td>0.249676</td>\n",
              "      <td>0.497674</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.233422</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.005884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>0.110235</td>\n",
              "      <td>0.346851</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264659</td>\n",
              "      <td>0.252656</td>\n",
              "      <td>0.313299</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>0.479452</td>\n",
              "      <td>0.016442</td>\n",
              "      <td>0.249452</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259663</td>\n",
              "      <td>0.237209</td>\n",
              "      <td>0.343874</td>\n",
              "      <td>0.238727</td>\n",
              "      <td>0.247191</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.014384</td>\n",
              "      <td>0.471982</td>\n",
              "      <td>0.267319</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234086</td>\n",
              "      <td>0.218418</td>\n",
              "      <td>0.314351</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.315068</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.296545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261698</td>\n",
              "      <td>0.818605</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.466844</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.001635</td>\n",
              "      <td>0.450629</td>\n",
              "      <td>0.802103</td>\n",
              "      <td>0.069611</td>\n",
              "      <td>0.162902</td>\n",
              "      <td>0.139315</td>\n",
              "      <td>0.300859</td>\n",
              "      <td>0.292308</td>\n",
              "      <td>0.246575</td>\n",
              "      <td>0.013234</td>\n",
              "      <td>0.360433</td>\n",
              "      <td>0.069611</td>\n",
              "      <td>0.249676</td>\n",
              "      <td>0.497674</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.233422</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.005884</td>\n",
              "      <td>0.387533</td>\n",
              "      <td>0.262355</td>\n",
              "      <td>0.009780</td>\n",
              "      <td>0.342231</td>\n",
              "      <td>0.349469</td>\n",
              "      <td>0.440687</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.534247</td>\n",
              "      <td>0.006433</td>\n",
              "      <td>0.377365</td>\n",
              "      <td>0.009780</td>\n",
              "      <td>0.381542</td>\n",
              "      <td>0.441860</td>\n",
              "      <td>0.470356</td>\n",
              "      <td>0.424403</td>\n",
              "      <td>0.438202</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.001635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>0.471982</td>\n",
              "      <td>0.267319</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234086</td>\n",
              "      <td>0.218418</td>\n",
              "      <td>0.314351</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.315068</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.296545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261698</td>\n",
              "      <td>0.818605</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.466844</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.001635</td>\n",
              "      <td>0.450629</td>\n",
              "      <td>0.802103</td>\n",
              "      <td>0.069611</td>\n",
              "      <td>0.162902</td>\n",
              "      <td>0.139315</td>\n",
              "      <td>0.300859</td>\n",
              "      <td>0.292308</td>\n",
              "      <td>0.246575</td>\n",
              "      <td>0.013234</td>\n",
              "      <td>0.360433</td>\n",
              "      <td>0.069611</td>\n",
              "      <td>0.249676</td>\n",
              "      <td>0.497674</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.233422</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.005884</td>\n",
              "      <td>0.387533</td>\n",
              "      <td>0.262355</td>\n",
              "      <td>0.009780</td>\n",
              "      <td>0.342231</td>\n",
              "      <td>0.349469</td>\n",
              "      <td>0.440687</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.534247</td>\n",
              "      <td>0.006433</td>\n",
              "      <td>0.377365</td>\n",
              "      <td>0.009780</td>\n",
              "      <td>0.381542</td>\n",
              "      <td>0.441860</td>\n",
              "      <td>0.470356</td>\n",
              "      <td>0.424403</td>\n",
              "      <td>0.438202</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.001635</td>\n",
              "      <td>0.283407</td>\n",
              "      <td>0.381873</td>\n",
              "      <td>0.043420</td>\n",
              "      <td>0.242984</td>\n",
              "      <td>0.239669</td>\n",
              "      <td>0.379008</td>\n",
              "      <td>0.246154</td>\n",
              "      <td>0.438356</td>\n",
              "      <td>0.061350</td>\n",
              "      <td>0.397861</td>\n",
              "      <td>0.043420</td>\n",
              "      <td>0.319586</td>\n",
              "      <td>0.269767</td>\n",
              "      <td>0.298419</td>\n",
              "      <td>0.220159</td>\n",
              "      <td>0.303371</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.100360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>931 rows × 72 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2   ...        69        70        71\n",
              "0    0.578732  0.506411  0.031797  ...  0.741573  0.705128  0.013076\n",
              "1    0.637045  0.431714  0.058423  ...  0.932584  0.782051  0.018960\n",
              "2    0.564377  0.444793  0.088428  ...  0.865169  0.782051  0.127820\n",
              "3    0.678953  0.618401  0.039324  ...  0.617978  0.705128  0.097091\n",
              "4    0.736552  0.663403  0.019252  ...  0.808989  0.641026  0.068977\n",
              "..        ...       ...       ...  ...       ...       ...       ...\n",
              "926  0.265885  0.632176  0.000000  ...  0.247191  0.564103  0.014384\n",
              "927  0.374852  0.445983  0.000000  ...  0.370787  0.358974  0.001635\n",
              "928  0.303140  0.508115  0.000000  ...  0.370787  0.423077  0.005884\n",
              "929  0.110235  0.346851  0.000000  ...  0.438202  0.564103  0.001635\n",
              "930  0.471982  0.267319  0.000000  ...  0.303371  0.500000  0.100360\n",
              "\n",
              "[931 rows x 72 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31wdXg6jokz_"
      },
      "source": [
        "\n",
        "from keras import backend \n",
        "backend.set_value(model.optimizer.learning_rate, 0.00001)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9zR35uKHvNu",
        "outputId": "447009e0-f97c-47c8-ea97-0422210ed9cc"
      },
      "source": [
        "history = model.fit(\n",
        "    x=XSJ_scale,\n",
        "    y=ySJ_scale,\n",
        "    validation_split=0.1,\n",
        "    epochs=100,\n",
        "    batch_size=1,\n",
        "    callbacks=callbacks,shuffle=False\n",
        "   )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "837/837 [==============================] - 28s 17ms/step - loss: 0.0697 - val_loss: 0.0112\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01124, saving model to ./model___1_0.03951_0.01124_.hdf5\n",
            "Epoch 2/100\n",
            "837/837 [==============================] - 14s 16ms/step - loss: 0.0193 - val_loss: 0.0082\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01124 to 0.00821, saving model to ./model___2_0.01732_0.00821_.hdf5\n",
            "Epoch 3/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0188 - val_loss: 0.0076\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00821 to 0.00761, saving model to ./model___3_0.01650_0.00761_.hdf5\n",
            "Epoch 4/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0189 - val_loss: 0.0074\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00761 to 0.00736, saving model to ./model___4_0.01642_0.00736_.hdf5\n",
            "Epoch 5/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0186 - val_loss: 0.0072\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00736 to 0.00725, saving model to ./model___5_0.01602_0.00725_.hdf5\n",
            "Epoch 6/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0182 - val_loss: 0.0071\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00725 to 0.00708, saving model to ./model___6_0.01581_0.00708_.hdf5\n",
            "Epoch 7/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0180 - val_loss: 0.0069\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00708 to 0.00690, saving model to ./model___7_0.01559_0.00690_.hdf5\n",
            "Epoch 8/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0175 - val_loss: 0.0068\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00690 to 0.00676, saving model to ./model___8_0.01526_0.00676_.hdf5\n",
            "Epoch 9/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0174 - val_loss: 0.0066\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00676 to 0.00660, saving model to ./model___9_0.01507_0.00660_.hdf5\n",
            "Epoch 10/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0170 - val_loss: 0.0065\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00660 to 0.00645, saving model to ./model___10_0.01481_0.00645_.hdf5\n",
            "Epoch 11/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0170 - val_loss: 0.0063\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00645 to 0.00631, saving model to ./model___11_0.01470_0.00631_.hdf5\n",
            "Epoch 12/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0168 - val_loss: 0.0062\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00631 to 0.00616, saving model to ./model___12_0.01458_0.00616_.hdf5\n",
            "Epoch 13/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0167 - val_loss: 0.0060\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00616 to 0.00602, saving model to ./model___13_0.01453_0.00602_.hdf5\n",
            "Epoch 14/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0165 - val_loss: 0.0059\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00602 to 0.00591, saving model to ./model___14_0.01424_0.00591_.hdf5\n",
            "Epoch 15/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0162 - val_loss: 0.0058\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00591 to 0.00580, saving model to ./model___15_0.01404_0.00580_.hdf5\n",
            "Epoch 16/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0161 - val_loss: 0.0057\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00580 to 0.00571, saving model to ./model___16_0.01397_0.00571_.hdf5\n",
            "Epoch 17/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0162 - val_loss: 0.0056\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00571 to 0.00561, saving model to ./model___17_0.01391_0.00561_.hdf5\n",
            "Epoch 18/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0157 - val_loss: 0.0056\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00561 to 0.00557, saving model to ./model___18_0.01364_0.00557_.hdf5\n",
            "Epoch 19/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0159 - val_loss: 0.0055\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00557 to 0.00547, saving model to ./model___19_0.01369_0.00547_.hdf5\n",
            "Epoch 20/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0158 - val_loss: 0.0054\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00547 to 0.00541, saving model to ./model___20_0.01359_0.00541_.hdf5\n",
            "Epoch 21/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0155 - val_loss: 0.0054\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00541 to 0.00538, saving model to ./model___21_0.01348_0.00538_.hdf5\n",
            "Epoch 22/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0160 - val_loss: 0.0053\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00538 to 0.00529, saving model to ./model___22_0.01366_0.00529_.hdf5\n",
            "Epoch 23/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0156 - val_loss: 0.0053\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00529 to 0.00527, saving model to ./model___23_0.01343_0.00527_.hdf5\n",
            "Epoch 24/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0157 - val_loss: 0.0052\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00527 to 0.00520, saving model to ./model___24_0.01350_0.00520_.hdf5\n",
            "Epoch 25/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0159 - val_loss: 0.0051\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00520 to 0.00514, saving model to ./model___25_0.01357_0.00514_.hdf5\n",
            "Epoch 26/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0160 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00514 to 0.00505, saving model to ./model___26_0.01364_0.00505_.hdf5\n",
            "Epoch 27/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0157 - val_loss: 0.0051\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00505\n",
            "Epoch 28/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0154 - val_loss: 0.0051\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00505\n",
            "Epoch 29/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0153 - val_loss: 0.0051\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00505\n",
            "Epoch 30/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0154 - val_loss: 0.0051\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00505\n",
            "Epoch 31/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0156 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.00505 to 0.00503, saving model to ./model___31_0.01327_0.00503_.hdf5\n",
            "Epoch 32/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0156 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.00503 to 0.00502, saving model to ./model___32_0.01326_0.00502_.hdf5\n",
            "Epoch 33/100\n",
            "837/837 [==============================] - 14s 17ms/step - loss: 0.0154 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.00502 to 0.00501, saving model to ./model___33_0.01315_0.00501_.hdf5\n",
            "Epoch 34/100\n",
            "837/837 [==============================] - 15s 17ms/step - loss: 0.0153 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00501\n",
            "Epoch 35/100\n",
            "837/837 [==============================] - 15s 17ms/step - loss: 0.0153 - val_loss: 0.0049\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00501 to 0.00494, saving model to ./model___35_0.01308_0.00494_.hdf5\n",
            "Epoch 36/100\n",
            "837/837 [==============================] - 14s 17ms/step - loss: 0.0152 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00494\n",
            "Epoch 37/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0152 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00494\n",
            "Epoch 38/100\n",
            "837/837 [==============================] - 14s 16ms/step - loss: 0.0155 - val_loss: 0.0049\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00494\n",
            "Epoch 39/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0153 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00494\n",
            "Epoch 40/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0151 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00494\n",
            "Epoch 41/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0152 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00494\n",
            "Epoch 42/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0154 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00494\n",
            "Epoch 43/100\n",
            "837/837 [==============================] - 14s 17ms/step - loss: 0.0154 - val_loss: 0.0049\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00494 to 0.00494, saving model to ./model___43_0.01310_0.00494_.hdf5\n",
            "Epoch 44/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0154 - val_loss: 0.0049\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.00494 to 0.00494, saving model to ./model___44_0.01307_0.00494_.hdf5\n",
            "Epoch 45/100\n",
            "837/837 [==============================] - 14s 16ms/step - loss: 0.0150 - val_loss: 0.0051\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00494\n",
            "Epoch 46/100\n",
            "837/837 [==============================] - 14s 16ms/step - loss: 0.0152 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00494\n",
            "Epoch 47/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0151 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00494\n",
            "Epoch 48/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0151 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00494\n",
            "Epoch 49/100\n",
            "837/837 [==============================] - 14s 16ms/step - loss: 0.0153 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00494\n",
            "Epoch 50/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0149 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00494\n",
            "Epoch 51/100\n",
            "837/837 [==============================] - 14s 16ms/step - loss: 0.0153 - val_loss: 0.0049\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.00494 to 0.00493, saving model to ./model___51_0.01300_0.00493_.hdf5\n",
            "Epoch 52/100\n",
            "837/837 [==============================] - 14s 16ms/step - loss: 0.0149 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00493\n",
            "Epoch 53/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0145 - val_loss: 0.0051\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.00493\n",
            "Epoch 54/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0148 - val_loss: 0.0051\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00493\n",
            "Epoch 55/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0149 - val_loss: 0.0051\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00493\n",
            "Epoch 56/100\n",
            "837/837 [==============================] - 13s 16ms/step - loss: 0.0147 - val_loss: 0.0052\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00493\n",
            "Epoch 57/100\n",
            "837/837 [==============================] - 14s 16ms/step - loss: 0.0150 - val_loss: 0.0050\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00493\n",
            "Epoch 58/100\n",
            "361/837 [===========>..................] - ETA: 7s - loss: 0.0125"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL5Wr_NkdsN0"
      },
      "source": [
        "def grafikon(fx,ind,desc1,txt1,desc2=\"\",txt2=\"\",desc3=\"\",txt3=\"\",ngraf=2,c1='rgba(35,128,132,0.8)', c2='rgba(193,99,99,0.8)',c3='rgba(193,99,0,0.8)',title=None):\n",
        "    '''\n",
        "    fx: dataFrame\n",
        "    ind: index\n",
        "    desc1:column1\n",
        "    txt1: label1\n",
        "    desc2:column2\n",
        "    txt2: label2\n",
        "    ngraf: number of graph\n",
        "    c1: color1\n",
        "    c2: color2\n",
        "    title: graph title\n",
        "    '''\n",
        "    \n",
        "    #x_=[i for i in range(len(y_pred))]\n",
        "    if title==None:\n",
        "      title=txt1+txt2\n",
        "    import plotly.express as px\n",
        "    import plotly.graph_objects as go\n",
        "    from plotly.subplots import make_subplots\n",
        "    fig0 = make_subplots(rows=1, cols=1)\n",
        "    \n",
        "    if True:\n",
        "        fig0.add_trace(\n",
        "            go.Scatter(x=fx[ind], y=fx[desc1], name=txt1, line=dict(color=c1) ,showlegend=True  ),\n",
        "\n",
        "            row=1, col=1\n",
        "\n",
        "        )\n",
        "    \n",
        "    if ngraf>1:\n",
        "        fig0.add_trace(\n",
        "            go.Scatter(x=fx[ind], y=fx[desc2], name=txt2, line=dict(color=c2) ,showlegend=True  ),\n",
        "\n",
        "            row=1, col=1\n",
        "        )\n",
        "    if ngraf>2:\n",
        "        fig0.add_trace(\n",
        "            go.Scatter(x=fx[ind], y=fx[desc3], name=txt3, line=dict(color=c3) ,showlegend=True  ),\n",
        "\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    fig0.update_layout(\n",
        "        title=title,\n",
        "        autosize=False,\n",
        "        width=1200,\n",
        "        height=600,\n",
        "        \n",
        "        )\n",
        "\n",
        "    fig0.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FAjyiKgpoij"
      },
      "source": [
        "#model_loaded=tf.keras.models.load_model('model___658_0.03376_0.01999_.hdf5',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QCA3rvVGLXL"
      },
      "source": [
        "model_loaded=model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdlFfbUiWvra"
      },
      "source": [
        "y_pred=model_loaded.predict(XSJ_scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdZLGOUfXGpi"
      },
      "source": [
        "y_pred[1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck4uVgpwJzLH"
      },
      "source": [
        "def backtest_train():\n",
        "    y_orig=ySJ_scale\n",
        "    output=pd.DataFrame(y_pred)\n",
        "    output[\"a\"]=y_orig\n",
        "    output.columns=[\"pred\",\"orig\"]\n",
        "    output[\"index\"]=range(0,len(y_orig))\n",
        "    grafikon(output,\"index\",\"orig\",\"orig\",\"pred\",\"pred\")\n",
        "\n",
        "def backtest_test():\n",
        "    y_orig=ySJ_scale\n",
        "    output=pd.DataFrame(y_pred)\n",
        "    output[\"a\"]=y_orig\n",
        "    output.columns=[\"pred\",\"orig\"]\n",
        "    output[\"index\"]=range(0,len(y_orig))\n",
        "    grafikon(output,\"index\",\"orig\",\"orig\",\"pred\",\"pred\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnlcf3ie3Mav"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQpwk-qY7j5Y"
      },
      "source": [
        "backtest_train()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}